{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNV1z8npzQRKqt+zTZnuVsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reusezer/Neuron-activations/blob/main/Qwen_hooks_with_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKnyCvTpZN6O"
      },
      "outputs": [],
      "source": [
        "# 1-1. upgrade pip (optional)\n",
        "!pip install -q --upgrade pip\n",
        "\n",
        "# 1-2. core libs: HF Transformers, accelerate (for device mapping), pandas, datasets, torch\n",
        "!pip install -q transformers accelerate pandas datasets torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# choose GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "Fw7ILKK8ZS-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"Qwen/Qwen3-8B\"\n",
        "\n",
        "# tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# HF model\n",
        "hf_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "hf_model.eval()\n"
      ],
      "metadata": {
        "id": "3Yd7h6L0ZUNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_URL = \"https://raw.githubusercontent.com/nyu-mll/crows-pairs/master/data/crows_pairs_anonymized.csv\"\n",
        "csv_path = \"crows_pairs_anonymized.csv\"\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(CSV_URL, csv_path)\n",
        "\n",
        "df = pd.read_csv(csv_path).dropna(subset=[\"sent_more\",\"sent_less\"])\n",
        "print(\"Total pairs loaded:\", len(df))\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "SJM_IDJ7ZWG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = df.sample(1).iloc[0]\n",
        "sent_more, sent_less = row[\"sent_more\"], row[\"sent_less\"]\n",
        "\n",
        "print(\"MORE (biased):\", sent_more)\n",
        "print(\"LESS (neutral):\", sent_less)\n"
      ],
      "metadata": {
        "id": "cehavb1mZXM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all submodules whose name contains \"mlp\" and are Linear layers:\n",
        "for name, module in hf_model.named_modules():\n",
        "    if \"mlp\" in name.lower() and isinstance(module, torch.nn.Linear):\n",
        "        print(f\"{name:60s} — weight shape: {tuple(module.weight.shape)}\")\n"
      ],
      "metadata": {
        "id": "mt8oA3I5ZYRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: Define known-working down_proj layers for Qwen3-8B (layers 27–35)\n",
        "HOOKED_MODULES = [\n",
        "    f\"model.layers.{i}.mlp.down_proj\" for i in range(27, 36)\n",
        "]\n",
        "print(\"Hooking modules:\")\n",
        "for m in HOOKED_MODULES:\n",
        "    print(\"  \", m)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6d9QcDwzhlRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        "\n",
        "def get_activations(prompt: str):\n",
        "    activations = defaultdict(list)\n",
        "\n",
        "    def make_hook(name):\n",
        "        def hook(module, input, output):\n",
        "            activations[name].append(output.detach().cpu())\n",
        "        return hook\n",
        "\n",
        "    # Register hooks on each relevant layer\n",
        "    hooks = []\n",
        "    for name, module in hf_model.named_modules():\n",
        "        if name in HOOKED_MODULES:\n",
        "            hooks.append(module.register_forward_hook(make_hook(name)))\n",
        "\n",
        "    # Forward pass\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        hf_model(**inputs)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    # Flatten hook outputs\n",
        "    return {\n",
        "        name: torch.cat(acts, dim=0) for name, acts in activations.items()\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "X2gTQ-9QhpFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "records = []\n",
        "\n",
        "# ✅ Loop through every CrowS-Pairs row\n",
        "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Comparing CrowS-Pairs\"):\n",
        "    try:\n",
        "        sent_more = row[\"sent_more\"]\n",
        "        sent_less = row[\"sent_less\"]\n",
        "\n",
        "        act_more = get_activations(sent_more)\n",
        "        act_less = get_activations(sent_less)\n",
        "\n",
        "        for name in HOOKED_MODULES:\n",
        "            if name in act_more and name in act_less:\n",
        "                min_len = min(act_more[name].shape[1], act_less[name].shape[1])\n",
        "                delta = (act_more[name][:, :min_len, :] - act_less[name][:, :min_len, :]).abs().mean(dim=(0, 1))\n",
        "\n",
        "                topk = torch.topk(delta, 5)\n",
        "\n",
        "                for idx, val in zip(topk.indices.tolist(), topk.values.tolist()):\n",
        "                    records.append({\n",
        "                        \"module\": name,\n",
        "                        \"layer\": int(name.split(\".\")[2]),\n",
        "                        \"neuron_index\": idx,\n",
        "                        \"delta_value\": float(val),\n",
        "                        \"prompt_more\": sent_more,\n",
        "                        \"prompt_less\": sent_less\n",
        "                    })\n",
        "    except Exception as e:\n",
        "        print(f\"❗ Error on row: {e}\")\n",
        "\n",
        "# ✅ Save to CSV\n",
        "if records:\n",
        "    df_out = pd.DataFrame(records)\n",
        "    output_path = \"crows_bias_top_neurons.csv\"\n",
        "    df_out.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Saved {len(df_out)} rows to {output_path}\")\n",
        "    files.download(output_path)\n",
        "else:\n",
        "    print(\"⚠️ No neuron activations recorded.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yh8Jj2Xhhp_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "records = []\n",
        "\n",
        "# Sample just 10 examples for now (fast test)\n",
        "sampled_df = df.sample(10, random_state=42)\n",
        "\n",
        "for _, row in tqdm(sampled_df.iterrows(), total=len(sampled_df), desc=\"Comparing Pairs\"):\n",
        "    try:\n",
        "        more, less = row[\"sent_more\"], row[\"sent_less\"]\n",
        "        act_more = get_activations(more)\n",
        "        act_less = get_activations(less)\n",
        "\n",
        "        for name in HOOKED_MODULES:\n",
        "            if name in act_more and name in act_less:\n",
        "                delta = (act_more[name] - act_less[name]).abs().mean(dim=(0, 1))\n",
        "                topk = torch.topk(delta, 5)\n",
        "                for idx, val in zip(topk.indices.tolist(), topk.values.tolist()):\n",
        "                    records.append({\n",
        "                        \"module\": name,\n",
        "                        \"layer\": int(name.split(\".\")[2]),\n",
        "                        \"neuron_index\": idx,\n",
        "                        \"delta_value\": float(val),\n",
        "                        \"prompt_more\": more,\n",
        "                        \"prompt_less\": less\n",
        "                    })\n",
        "    except Exception as e:\n",
        "        print(f\"❗ Error with pair: {e}\")\n",
        "\n",
        "# Save if any records\n",
        "if records:\n",
        "    df_out = pd.DataFrame(records)\n",
        "    out_path = \"crows_bias_top_neurons.csv\"\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "    print(f\"✅ Saved {len(df_out)} rows to {out_path}\")\n",
        "    files.download(out_path)\n",
        "else:\n",
        "    print(\"⚠️ No neuron deltas recorded. Check hook layer matches.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XguNv1K6hmEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your updated CSV\n",
        "df = pd.read_csv(\"/content/crows_bias_top_neurons (1).csv\")\n",
        "\n",
        "# Aggregate: mean delta per neuron per layer\n",
        "df[\"layer\"] = df[\"module\"].str.extract(r\"layers\\.(\\d+)\")\n",
        "df[\"layer\"] = df[\"layer\"].astype(int)\n",
        "\n",
        "pivot = df.pivot_table(\n",
        "    index=\"layer\",\n",
        "    columns=\"neuron_index\",\n",
        "    values=\"delta_value\",\n",
        "    aggfunc=\"mean\"\n",
        ").fillna(0)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(pivot, cmap=\"viridis\", xticklabels=False)\n",
        "plt.title(\"Bias-Activated Neurons by Layer (mean ∆ activation)\")\n",
        "plt.xlabel(\"Neuron Index\")\n",
        "plt.ylabel(\"Layer\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "SiJcudw0l7hF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}