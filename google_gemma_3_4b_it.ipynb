{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reusezer/Neuron-activations/blob/main/google_gemma_3_4b_it.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKnyCvTpZN6O"
      },
      "outputs": [],
      "source": [
        "# 1-1. upgrade pip (optional)\n",
        "!pip install -q --upgrade pip\n",
        "\n",
        "# 1-2. core libs: HF Transformers, accelerate (for device mapping), pandas, datasets, torch\n",
        "!pip install -q transformers accelerate pandas datasets torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw7ILKK8ZS-C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# choose GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yd7h6L0ZUNV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "hf_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,  # ✅ corrected\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "hf_model.eval()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJM_IDJ7ZWG9"
      },
      "outputs": [],
      "source": [
        "CSV_URL = \"https://raw.githubusercontent.com/nyu-mll/crows-pairs/master/data/crows_pairs_anonymized.csv\"\n",
        "csv_path = \"crows_pairs_anonymized.csv\"\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(CSV_URL, csv_path)\n",
        "\n",
        "df = pd.read_csv(csv_path).dropna(subset=[\"sent_more\",\"sent_less\"])\n",
        "print(\"Total pairs loaded:\", len(df))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cehavb1mZXM3"
      },
      "outputs": [],
      "source": [
        "row = df.sample(1).iloc[0]\n",
        "sent_more, sent_less = row[\"sent_more\"], row[\"sent_less\"]\n",
        "\n",
        "print(\"MORE (biased):\", sent_more)\n",
        "print(\"LESS (neutral):\", sent_less)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt8oA3I5ZYRI"
      },
      "outputs": [],
      "source": [
        "# List all submodules whose name contains \"mlp\" and are Linear layers:\n",
        "for name, module in hf_model.named_modules():\n",
        "    if \"mlp\" in name.lower() and isinstance(module, torch.nn.Linear):\n",
        "        print(f\"{name:60s} — weight shape: {tuple(module.weight.shape)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d9QcDwzhlRR"
      },
      "outputs": [],
      "source": [
        "# Cell A (generic for any model)\n",
        "HOOKED_MODULES = [\n",
        "    name for name, module in hf_model.named_modules()\n",
        "    if name.endswith(\"mlp.down_proj\")\n",
        "]\n",
        "\n",
        "print(\"✅ Hooking the following MLP output layers:\")\n",
        "for m in HOOKED_MODULES:\n",
        "    print(\"  \", m)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2gTQ-9QhpFG"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        "\n",
        "def get_activations(prompt: str):\n",
        "    activations = defaultdict(list)\n",
        "\n",
        "    def make_hook(name):\n",
        "        def hook(module, input, output):\n",
        "            if isinstance(output, torch.Tensor):\n",
        "                activations[name].append(output.detach().cpu())\n",
        "        return hook\n",
        "\n",
        "    hooks = []\n",
        "    for name, module in hf_model.named_modules():\n",
        "        if name in HOOKED_MODULES:\n",
        "            hooks.append(module.register_forward_hook(make_hook(name)))\n",
        "\n",
        "    tokens = tokenizer(prompt, return_tensors=\"pt\").to(hf_model.device)\n",
        "    with torch.no_grad():\n",
        "        _ = hf_model(**tokens)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    return {k: torch.cat(v, dim=0) for k, v in activations.items()}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh8Jj2Xhhp_H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "#  Auto-detect all MLP down_proj layers in the loaded model\n",
        "HOOKED_MODULES = [\n",
        "    name for name, module in hf_model.named_modules()\n",
        "    if name.endswith(\"mlp.down_proj\")\n",
        "]\n",
        "print(\"✅ Hooking the following MLP output layers:\")\n",
        "for m in HOOKED_MODULES:\n",
        "    print(\"  \", m)\n",
        "\n",
        "records = []\n",
        "\n",
        "#  Loop through every CrowS-Pairs row\n",
        "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Comparing CrowS-Pairs\"):\n",
        "    try:\n",
        "        sent_more = row[\"sent_more\"]\n",
        "        sent_less = row[\"sent_less\"]\n",
        "\n",
        "        act_more = get_activations(sent_more)\n",
        "        act_less = get_activations(sent_less)\n",
        "\n",
        "        for name in HOOKED_MODULES:\n",
        "            if name in act_more and name in act_less:\n",
        "                min_len = min(act_more[name].shape[1], act_less[name].shape[1])\n",
        "                delta = (act_more[name][:, :min_len, :] - act_less[name][:, :min_len, :]).abs().mean(dim=(0, 1))\n",
        "                topk = torch.topk(delta, 5)\n",
        "\n",
        "                # ✅ Robust layer index extraction\n",
        "                try:\n",
        "                  parts = name.split(\".\")\n",
        "                  layer_index = int(parts[parts.index(\"layers\") + 1])\n",
        "                except:\n",
        "                  layer_index = -1\n",
        "\n",
        "\n",
        "                for idx, val in zip(topk.indices.tolist(), topk.values.tolist()):\n",
        "                    records.append({\n",
        "                        \"module\": name,\n",
        "                        \"layer\": layer_index,\n",
        "                        \"neuron_index\": idx,\n",
        "                        \"delta_value\": float(val),\n",
        "                        \"prompt_more\": sent_more,\n",
        "                        \"prompt_less\": sent_less\n",
        "                    })\n",
        "    except Exception as e:\n",
        "        print(f\"❗ Error on row: {e}\")\n",
        "\n",
        "#  Save to CSV\n",
        "if records:\n",
        "    df_out = pd.DataFrame(records)\n",
        "    output_path = \"crows_bias_top_neurons.csv\"\n",
        "    df_out.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Saved {len(df_out)} rows to {output_path}\")\n",
        "    files.download(output_path)\n",
        "else:\n",
        "    print(\"⚠️ No neuron activations recorded.\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiJcudw0l7hF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your updated CSV\n",
        "df = pd.read_csv(\"/content/crows_bias_top_neurons.csv\")\n",
        "\n",
        "# Aggregate: mean delta per neuron per layer\n",
        "df[\"layer\"] = df[\"module\"].str.extract(r\"layers\\.(\\d+)\")\n",
        "df[\"layer\"] = df[\"layer\"].astype(int)\n",
        "\n",
        "pivot = df.pivot_table(\n",
        "    index=\"layer\",\n",
        "    columns=\"neuron_index\",\n",
        "    values=\"delta_value\",\n",
        "    aggfunc=\"mean\"\n",
        ").fillna(0)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(pivot, cmap=\"viridis\", xticklabels=False)\n",
        "plt.title(\"Bias-Activated Neurons by Layer (mean ∆ activation)\")\n",
        "plt.xlabel(\"Neuron Index\")\n",
        "plt.ylabel(\"Layer\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyOvvCnuZE1stVwLD87QfG1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}